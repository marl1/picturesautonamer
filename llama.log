[1704661950] Multi Modal Mode Enabled[1704661951] warming up the model with an empty run
[1704661953] Available slots:
[1704661953]  -> Slot 0 - max context: 2048
[1704661953] 
llama server listening at http://127.0.0.1:8080

[1704661953] all slots are idle and system prompt is empty, clear the KV cache
[1704661953] slot 0 - image loaded [id: 1] resolution (300 x 289)
[1704661953] slot 0 is processing [task id: 0]
[1704661953] slot 0 : kv cache rm - [0, end)
[1704661953] slot 0 - encoding image [id: 1]
[1704661974] sampled token:   920: ' how'
[1704661975] sampled token: 29899: '-'
[1704661975] sampled token:   517: 'to'
[1704661976] sampled token: 29899: '-'
[1704661976] sampled token:  1509: 'use'
[1704661977] sampled token: 29899: '-'
[1704661977] sampled token:   273: 'an'
[1704661977] sampled token: 29899: '-'
[1704661978] sampled token: 29872: 'e'
[1704661978] sampled token:  2608: 'lev'
[1704661979] sampled token:  1061: 'ator'
[1704661979] sampled token: 29899: '-'
[1704661979] sampled token: 14037: 'without'
[1704661980] sampled token: 29899: '-'
[1704661980] sampled token:  7864: 'sto'
[1704661981] sampled token:  3262: 'pping'
[1704661981] sampled token: 29889: '.'
[1704661982] sampled token:     2: ''
[1704661982] 
[1704661982] print_timings: prompt eval time =   21905.21 ms /     1 tokens (21905.21 ms per token,     0.05 tokens per second)
[1704661982] print_timings:        eval time =    6712.84 ms /    17 runs   (  394.87 ms per token,     2.53 tokens per second)
[1704661982] print_timings:       total time =   28618.05 ms
[1704661982] slot 0 released (19 tokens in cache)
